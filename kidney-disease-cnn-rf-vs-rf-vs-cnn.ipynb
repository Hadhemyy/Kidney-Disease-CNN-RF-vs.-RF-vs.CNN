{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport pandas as pd\n\nimport cv2\nimport matplotlib\nimport matplotlib.pylab as plt\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.utils import shuffle\n#   DataGenerator to read images and rescale images\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n#   count each class samples\nfrom collections import Counter\nimport random\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import accuracy_score, classification_report\n \n# Different layers\nfrom keras.models import Sequential\nfrom keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import Convolution2D\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import ReLU\nfrom tensorflow.keras.layers import Softmax\nfrom keras.initializers import GlorotUniformV2\n\n\n","metadata":{"id":"U-GFnz9B7Ryv","outputId":"c70e2c06-30ff-4bf1-c6d9-8c43018ac38f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation and Data Loading ","metadata":{}},{"cell_type":"code","source":"## Set Path Here before running the code\nWORKING_DIRECTORY =  \"/kaggle/input/kidney-diseases-recognition/dataset\"\n##  Name of classes\nCLASSES = ['Cyst',\n           'Normal',\n           'Stone',\n           'Tumor']","metadata":{"id":"66VfAAIS9k0t","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Define your data augmentation parameters\ndatagen = ImageDataGenerator(\n    rescale=1.0/255.0,\n    horizontal_flip=True,\n    width_shift_range=0.2,\n \n)\n\n\n\n# Load and augment images\ntrain_dataset = datagen.flow_from_directory(\n    WORKING_DIRECTORY,\n    target_size=(224, 224),\n    batch_size=200,\n    shuffle=True\n)\n\n# Separate dataset from Data Generator\nX, y = train_dataset.next()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samples_before = len(X)\nprint(\"Images shape :\\t\", X.shape)\nprint(\"Labels shape :\\t\", y.shape)","metadata":{"id":"sGH24uwSBjd_","outputId":"50d78ad1-0a08-461c-9d6b-4b79f54d6003","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Balancing Class Data \n","metadata":{}},{"cell_type":"code","source":"# SMOTE\nX = X.reshape(-1, 224 * 224 * 3)\nsmote = SMOTE(random_state=42)\nX, y = smote.fit_resample(X, y)\nX = X.reshape(-1, 224, 224, 3)\n\nprint(X.shape) \nprint(y.shape)  \n","metadata":{"id":"dfH_CHJQuQHv","outputId":"675a0425-b99d-4186-eaec-ac2853843caa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of samples in each class:\\t\", sorted(Counter(np.argmax(y, axis=1)).items()))\nprint(\"Classes Names according to index:\\t\", train_dataset.class_indices)","metadata":{"id":"L81vwqc6Bn2e","outputId":"9f27d415-1c3a-4b88-8305-29c8cfeb1b3e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization Data","metadata":{}},{"cell_type":"code","source":"#   show some images\nfig = plt.figure(figsize=(10,8))\n\nrows = 4\ncolumns = 4\n\nfor i in range(rows * columns):\n    fig.add_subplot(rows, columns, i+1)\n    num = random.randint(0, len(X)-1 )\n    plt.imshow(X[num])\n    plt.axis('off')\n    plt.title(CLASSES[(np.argmax(y[num]))], fontsize=8)\nplt.axis('off')\nplt.show()","metadata":{"id":"UiEmsV_mBxMO","outputId":"e8098eb9-ffd9-4051-a19f-95c32c2f0274","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Splitting Data ","metadata":{}},{"cell_type":"code","source":"#   20% split to validation and 80% split to train set\nX_train, x_test, y_train, y_test = train_test_split(X,y, test_size = 0.3)\nprint(\"Number of samples after splitting into Training, validation & test set\\n\")\nprint(\"Train     \\t\",sorted(Counter(np.argmax(y_train, axis=1)).items()))\nprint(\"Test      \\t\",sorted(Counter(np.argmax(y_test, axis=1)).items()))","metadata":{"id":"PnFfyGEbCCzv","outputId":"d1a0dcc3-d196-41e6-8ddb-b12dd8dc266c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"markdown","source":"* **RandomForest**","metadata":{}},{"cell_type":"code","source":"X_train_flattened = X_train.reshape(X_train.shape[0], -1)\nx_test_flattened = x_test.reshape(x_test.shape[0], -1)\nrf_classifier = RandomForestClassifier(n_estimators=25, random_state=42)\nrf_classifier.fit(X_train_flattened, y_train)\ny_pred = rf_classifier.predict(x_test_flattened)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")\n","metadata":{"id":"wMgbF0unW4sh","outputId":"a88618e7-6210-4cc0-d213-81ceda6805b1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **CNN**","metadata":{}},{"cell_type":"code","source":"init = GlorotUniformV2\nmodel = Sequential()\nmodel.add(Input(shape=(224, 224, 3)))\nmodel.add(Convolution2D(16, 5, kernel_initializer=init))\nmodel.add(ReLU())\nmodel.add(AveragePooling2D(pool_size=(2,2)))\nmodel.add(Convolution2D(32, 5, kernel_initializer=init))\nmodel.add(ReLU())\nmodel.add(AveragePooling2D(pool_size=(2,2)))\nmodel.add(Convolution2D(64, 5, kernel_initializer=init))\nmodel.add(ReLU())\nmodel.add(AveragePooling2D(pool_size=(2,2)))\nmodel.add(Convolution2D(128, 5, kernel_initializer=init))\nmodel.add(ReLU())\nmodel.add(AveragePooling2D(pool_size=(2,2)))\nmodel.add(Convolution2D(256, 5, kernel_initializer=init))\nmodel.add(ReLU())\nmodel.add(AveragePooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.01))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, kernel_initializer=init))\nmodel.add(ReLU())\nmodel.add(Dropout(0.03))\nmodel.add(Dense(4, kernel_initializer=init))\nmodel.add(Softmax())\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X_train, y_train, epochs=20, batch_size=16, validation_split=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate model \nloss, accuracy = model.evaluate(x_test, y_test)\nprint(f\"Test Loss: {loss:.2f}\")\nprint(f\"Test Accuracy: {accuracy:.2f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **CNN&RF**","metadata":{}},{"cell_type":"code","source":"init = GlorotUniformV2\ninput_shape=(224,224,3)\n\n#create the Network\nimg_imput = Input(shape = input_shape,name='img_imput')\nx=Convolution2D(16, 5, kernel_initializer=init , name='layer_1')(img_imput)\nx=ReLU()(x)\nx=AveragePooling2D(pool_size=(2,2), name='layer_2')(x)\nx=Convolution2D(32, 5, kernel_initializer=init, name='layer_43')(x)\nx=ReLU()(x)\nx=AveragePooling2D(pool_size=(2,2), name='layer_4')(x)\nx=Convolution2D(64, 5, kernel_initializer=init, name='layer_5')(x)\nx=ReLU()(x)\nx=AveragePooling2D(pool_size=(2,2), name='layer_6')(x)\nx=Convolution2D(128, 5, kernel_initializer=init , name='layer_7')(x)\nx=ReLU()(x)\nx=AveragePooling2D(pool_size=(2,2), name='layer_8')(x)\nx=Convolution2D(256, 5, kernel_initializer=init , name='layer_9')(x)\nx=ReLU()(x)\nx=AveragePooling2D(pool_size=(2,2), name='layer_10')(x)\nx=Dropout(0.25, name='layer_11')(x)\n\nx=Flatten(name='fc_1')(x)\nx=Dense(256, kernel_initializer=init, name='layer_12')(x)\nx=ReLU()(x)\nx=Dropout(0.25)(x)\n\n\n\nprint('feature:' , x)","metadata":{"id":"vF1AWqsJiaND","outputId":"c34e9d0b-fe7a-4a4e-a413-7841b80f966e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Generate the model\nmodel = Model(inputs=img_imput, outputs =x , name='multi_classification')\nprint(model.summary())","metadata":{"id":"aa51f8f5","outputId":"e495c205-ef0d-42c4-903e-1ac6a6330a0a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Feature extraction using CNN model\nfeaturesTrain= model.predict(X_train)\nfeaturesTrain= featuresTrain.reshape(featuresTrain.shape[0], -1)\nfeaturesVal= model.predict(x_test)\nfeaturesVal= featuresVal.reshape(featuresVal.shape[0], -1)","metadata":{"id":"092daacc","outputId":"73544acf-28b2-4a03-df9c-7fdd51a464ad","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_classifier.fit(featuresTrain, y_train)\ny_pred_rf = rf_classifier.predict(featuresVal)\n\naccuracy_rf = accuracy_score(y_test, y_pred_rf)\nprint(f\"Random Forest Accuracy: {accuracy_rf:.2f}\")","metadata":{"id":"BtM4xUP8KCNi","outputId":"45689281-d669-45f8-d007-f8fd3d492ac4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Performance Comparison of CNN, CNN+RF, RF ","metadata":{}},{"cell_type":"markdown","source":"The accuracy results indicate that the  **CNN** model performed the best with an accuracy of **0.85**, highlighting its effectiveness in image classification tasks. The **CNN+Random** Forest hybrid approach achieved a slightly lower accuracy of **0.67**, showcasing the potential benefits of combining deep feature learning (CNN) with ensemble-based decision-making (Random Forest). However, the **Random Forest** model lagged behind with an accuracy of **0.61**, suggesting it may not be the most suitable choice for this particular classification task. \nThe CNN model demonstrated superior performance, while the hybrid approach showed promise.","metadata":{}}]}